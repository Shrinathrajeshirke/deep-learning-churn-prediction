{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "### import libaries\n",
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "from nltk.corpus import gutenberg\n",
        "import pandas as pd\n",
        "\n",
        "## load the dataset\n",
        "data = gutenberg.raw('shakespeare-hamlet.txt')\n",
        "\n",
        "## save to file\n",
        "with open('hamlet.txt', 'w') as f:\n",
        "    f.write(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4DPsHgd-paG",
        "outputId": "d1b1ab59-4dbf-4afd-8e3b-c5ce8683f220"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## data preprocessing\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## load the dataset\n",
        "with open('hamlet.txt', 'r') as file:\n",
        "  text = file.read().lower()\n",
        "\n",
        "## tokenize the text - create index for word\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index)+1\n",
        "print(total_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqgYa5oD_j_Y",
        "outputId": "49e2ffe7-1fbf-4042-8ab1-f891b7781075"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## create input sequences\n",
        "inputsequences = []\n",
        "for line in text.split('\\n'):\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1,len(token_list)):\n",
        "    n_gram_seq = token_list[:i+1]\n",
        "    inputsequences.append(n_gram_seq)\n",
        "\n",
        "## padding sequences\n",
        "max_seq_len = max([len(x) for x in inputsequences])\n",
        "inputsequences=np.array(pad_sequences(inputsequences,maxlen=max_seq_len,padding='pre'))\n",
        "inputsequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKtTNPn_ArFc",
        "outputId": "8a9d7232-040a-4b48-db52-05695d1e862c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    0,    1,  687],\n",
              "       [   0,    0,    0, ...,    1,  687,    4],\n",
              "       [   0,    0,    0, ...,  687,    4,   45],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    4,   45, 1047],\n",
              "       [   0,    0,    0, ...,   45, 1047,    4],\n",
              "       [   0,    0,    0, ..., 1047,    4,  193]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### create predictors and label\n",
        "import tensorflow as tf\n",
        "x,y = inputsequences[:,:-1],inputsequences[:,-1]"
      ],
      "metadata": {
        "id": "SyLB-AkeB9bT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = tf.keras.utils.to_categorical(y,num_classes=total_words)"
      ],
      "metadata": {
        "id": "0tUHRMXbDvFz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)"
      ],
      "metadata": {
        "id": "Uq865rsdFmoY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## train lstm model\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import  Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "## define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length = max_seq_len-1))\n",
        "model.add(LSTM(150,return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words,activation='softmax'))\n",
        "\n",
        "##compile the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "WJjBAfQfD6K1",
        "outputId": "67261548-8afa-470d-a4d5-2b91d8a5be1f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## define early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss',patience=3,restore_best_weights=True)"
      ],
      "metadata": {
        "id": "avDAJMiGGP50"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history =model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test),verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JubGb3lSFJan",
        "outputId": "30339b0b-1359-4779-fe5c-fbac7941a225"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 73ms/step - accuracy: 0.0549 - loss: 6.1351 - val_accuracy: 0.0474 - val_loss: 6.9204\n",
            "Epoch 2/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 76ms/step - accuracy: 0.0551 - loss: 5.9292 - val_accuracy: 0.0497 - val_loss: 7.0064\n",
            "Epoch 3/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 72ms/step - accuracy: 0.0592 - loss: 5.8207 - val_accuracy: 0.0527 - val_loss: 7.0751\n",
            "Epoch 4/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 72ms/step - accuracy: 0.0694 - loss: 5.6769 - val_accuracy: 0.0587 - val_loss: 7.1400\n",
            "Epoch 5/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 72ms/step - accuracy: 0.0750 - loss: 5.5086 - val_accuracy: 0.0639 - val_loss: 7.1862\n",
            "Epoch 6/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 75ms/step - accuracy: 0.0809 - loss: 5.3826 - val_accuracy: 0.0670 - val_loss: 7.2655\n",
            "Epoch 7/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 71ms/step - accuracy: 0.0896 - loss: 5.2160 - val_accuracy: 0.0676 - val_loss: 7.3577\n",
            "Epoch 8/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 71ms/step - accuracy: 0.0965 - loss: 5.0961 - val_accuracy: 0.0663 - val_loss: 7.4913\n",
            "Epoch 9/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 71ms/step - accuracy: 0.0988 - loss: 4.9761 - val_accuracy: 0.0686 - val_loss: 7.5925\n",
            "Epoch 10/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 72ms/step - accuracy: 0.1118 - loss: 4.8151 - val_accuracy: 0.0678 - val_loss: 7.7100\n",
            "Epoch 11/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 72ms/step - accuracy: 0.1143 - loss: 4.6976 - val_accuracy: 0.0661 - val_loss: 7.8671\n",
            "Epoch 12/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 72ms/step - accuracy: 0.1303 - loss: 4.5414 - val_accuracy: 0.0670 - val_loss: 7.9901\n",
            "Epoch 13/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 73ms/step - accuracy: 0.1306 - loss: 4.4756 - val_accuracy: 0.0633 - val_loss: 8.1216\n",
            "Epoch 14/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 72ms/step - accuracy: 0.1464 - loss: 4.3376 - val_accuracy: 0.0645 - val_loss: 8.2491\n",
            "Epoch 15/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 72ms/step - accuracy: 0.1579 - loss: 4.2310 - val_accuracy: 0.0612 - val_loss: 8.3542\n",
            "Epoch 16/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 75ms/step - accuracy: 0.1731 - loss: 4.1099 - val_accuracy: 0.0618 - val_loss: 8.4887\n",
            "Epoch 17/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 73ms/step - accuracy: 0.1907 - loss: 4.0180 - val_accuracy: 0.0647 - val_loss: 8.6063\n",
            "Epoch 18/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 94ms/step - accuracy: 0.2021 - loss: 3.9425 - val_accuracy: 0.0612 - val_loss: 8.7050\n",
            "Epoch 19/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 99ms/step - accuracy: 0.2160 - loss: 3.8421 - val_accuracy: 0.0602 - val_loss: 8.8396\n",
            "Epoch 20/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 114ms/step - accuracy: 0.2341 - loss: 3.7609 - val_accuracy: 0.0575 - val_loss: 8.9529\n",
            "Epoch 21/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 107ms/step - accuracy: 0.2453 - loss: 3.6701 - val_accuracy: 0.0589 - val_loss: 9.0753\n",
            "Epoch 22/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 98ms/step - accuracy: 0.2663 - loss: 3.5766 - val_accuracy: 0.0606 - val_loss: 9.1564\n",
            "Epoch 23/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 104ms/step - accuracy: 0.2754 - loss: 3.4857 - val_accuracy: 0.0585 - val_loss: 9.2543\n",
            "Epoch 24/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 112ms/step - accuracy: 0.2931 - loss: 3.4179 - val_accuracy: 0.0585 - val_loss: 9.3609\n",
            "Epoch 25/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 96ms/step - accuracy: 0.2995 - loss: 3.3545 - val_accuracy: 0.0554 - val_loss: 9.4687\n",
            "Epoch 26/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 72ms/step - accuracy: 0.3130 - loss: 3.2808 - val_accuracy: 0.0558 - val_loss: 9.5268\n",
            "Epoch 27/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 72ms/step - accuracy: 0.3258 - loss: 3.2343 - val_accuracy: 0.0567 - val_loss: 9.6435\n",
            "Epoch 28/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 76ms/step - accuracy: 0.3281 - loss: 3.1978 - val_accuracy: 0.0546 - val_loss: 9.7134\n",
            "Epoch 29/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 72ms/step - accuracy: 0.3412 - loss: 3.1222 - val_accuracy: 0.0532 - val_loss: 9.8482\n",
            "Epoch 30/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 72ms/step - accuracy: 0.3468 - loss: 3.0726 - val_accuracy: 0.0567 - val_loss: 9.9325\n",
            "Epoch 31/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 73ms/step - accuracy: 0.3653 - loss: 2.9773 - val_accuracy: 0.0556 - val_loss: 10.0086\n",
            "Epoch 32/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 72ms/step - accuracy: 0.3743 - loss: 2.9355 - val_accuracy: 0.0554 - val_loss: 10.0612\n",
            "Epoch 33/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 72ms/step - accuracy: 0.3760 - loss: 2.9356 - val_accuracy: 0.0532 - val_loss: 10.1445\n",
            "Epoch 34/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 76ms/step - accuracy: 0.3881 - loss: 2.8583 - val_accuracy: 0.0567 - val_loss: 10.2525\n",
            "Epoch 35/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 72ms/step - accuracy: 0.3991 - loss: 2.8045 - val_accuracy: 0.0565 - val_loss: 10.3648\n",
            "Epoch 36/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 72ms/step - accuracy: 0.4104 - loss: 2.7442 - val_accuracy: 0.0569 - val_loss: 10.4124\n",
            "Epoch 37/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 72ms/step - accuracy: 0.4136 - loss: 2.7172 - val_accuracy: 0.0573 - val_loss: 10.4626\n",
            "Epoch 38/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 72ms/step - accuracy: 0.4195 - loss: 2.6793 - val_accuracy: 0.0536 - val_loss: 10.5556\n",
            "Epoch 39/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 72ms/step - accuracy: 0.4329 - loss: 2.6275 - val_accuracy: 0.0546 - val_loss: 10.6294\n",
            "Epoch 40/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 72ms/step - accuracy: 0.4376 - loss: 2.6018 - val_accuracy: 0.0552 - val_loss: 10.6740\n",
            "Epoch 41/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 73ms/step - accuracy: 0.4528 - loss: 2.5350 - val_accuracy: 0.0575 - val_loss: 10.7855\n",
            "Epoch 42/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 73ms/step - accuracy: 0.4525 - loss: 2.5062 - val_accuracy: 0.0560 - val_loss: 10.8279\n",
            "Epoch 43/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 72ms/step - accuracy: 0.4614 - loss: 2.4711 - val_accuracy: 0.0548 - val_loss: 10.8988\n",
            "Epoch 44/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 73ms/step - accuracy: 0.4769 - loss: 2.4215 - val_accuracy: 0.0552 - val_loss: 10.9671\n",
            "Epoch 45/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 72ms/step - accuracy: 0.4803 - loss: 2.3918 - val_accuracy: 0.0544 - val_loss: 11.0781\n",
            "Epoch 46/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 72ms/step - accuracy: 0.4854 - loss: 2.3653 - val_accuracy: 0.0544 - val_loss: 11.1082\n",
            "Epoch 47/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 72ms/step - accuracy: 0.4856 - loss: 2.3424 - val_accuracy: 0.0556 - val_loss: 11.1629\n",
            "Epoch 48/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 72ms/step - accuracy: 0.4952 - loss: 2.2892 - val_accuracy: 0.0552 - val_loss: 11.2243\n",
            "Epoch 49/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 72ms/step - accuracy: 0.5027 - loss: 2.2570 - val_accuracy: 0.0561 - val_loss: 11.2856\n",
            "Epoch 50/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 72ms/step - accuracy: 0.5090 - loss: 2.2310 - val_accuracy: 0.0556 - val_loss: 11.3413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## function to predict the next word\n",
        "\n",
        "def predict_next_word(model, tokenizer, text, max_sequence_len):\n",
        "  token_list = tokenizer.texts_to_sequences([text])[0]\n",
        "  if len(token_list) >= max_seq_len:\n",
        "    token_list = token_list[-(max_seq_len-1):]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_seq_len-1, padding='pre')\n",
        "  predicted = model.predict(token_list, verbose=0)\n",
        "  predicted_word_index = np.argmax(predicted, axis=1)\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted_word_index:\n",
        "      return word\n",
        "  return None"
      ],
      "metadata": {
        "id": "-JSU6ixPFvHL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"To be or not to be\"\n",
        "print(f\"input text: {input_text}\")\n",
        "max_sequence_len = model.input_shape[1]+1\n",
        "next_word = predict_next_word(model, tokenizer, input_text, max_sequence_len)\n",
        "print(f\"Next word prediction: {next_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS5XJVRBQVKV",
        "outputId": "e52b2160-3cdf-4cb7-9ab9-9ec77d04d821"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input text: To be or not to be\n",
            "Next word prediction: in't\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebT3H5Vydkpd",
        "outputId": "b9107654-f130-46d9-8a6b-fabe6212538f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a permanent path\n",
        "permanent_path = '/content/drive/MyDrive/Colab Notebooks/lstm.keras'\n",
        "\n",
        "# Save the model to the permanent location\n",
        "model.save(permanent_path)\n",
        "\n",
        "import pickle\n",
        "# Ensure the folder 'Colab_Notebooks' exists in your Google Drive\n",
        "save_path = '/content/drive/MyDrive/Colab Notebooks/tokenizer.pickle'\n",
        "\n",
        "with open(save_path, 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "print(f\"File saved successfully to: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3vE4MKoQxLC",
        "outputId": "be25d286-0fe0-4e74-95b1-277a50812e3f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved successfully to: /content/drive/MyDrive/Colab Notebooks/tokenizer.pickle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oMqtKErZcbE7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}